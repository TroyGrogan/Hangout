# ğŸš€ Quick Test Commands

## ğŸ“ **ALWAYS RUN FROM:** `backend` directory with virtual environment activated

```bash
cd backend
source ../env/bin/activate
```

## âš¡ **Most Common Commands**

### ğŸ¯ **Quick Test** (No Django, 30 seconds)
```bash
python apps/ai_chat/ai_test_scripts/simple_deployment_test.py
```

### ğŸ”¥ **Full Django Test** (With model loading, 2-3 minutes)
```bash
python apps/ai_chat/ai_test_scripts/test_django_integration.py
```

### ğŸ“Š **Memory Monitor** (Real-time, run in separate terminal)
```bash
python apps/ai_chat/ai_test_scripts/monitor_memory.py
```

### âœ… **Deployment Ready Check**
```bash
python apps/ai_chat/ai_test_scripts/verify_deployment_ready.py
```

---

## ğŸ¯ **Expected Results**
- âœ… Memory pressure: **low**
- âœ… Context window: **1024 tokens**
- âœ… Max response: **512 tokens**
- âœ… Response time: **2-10 seconds**
- âœ… Model loaded: **True**

---

## ğŸ› **If Something Fails**
1. Check virtual environment: `source ../env/bin/activate`
2. Check you're in backend directory: `pwd` should end with `/backend`
3. Check model file exists: `ls ai_model/tinyllama-1.1b-chat-v1.0.Q8_0.gguf` 